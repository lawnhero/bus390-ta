{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "import utils.chains_lcel as chains\n",
    "from utils.sidebar import sidebar\n",
    "import utils.llm_models as llms\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.messages.utils import convert_to_openai_messages, convert_to_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tools and Agent implementation for the Virtual TA system.\n",
    "\"\"\"\n",
    "\n",
    "from langchain.tools import StructuredTool\n",
    "from typing import Optional, List\n",
    "from langchain.schema.language_model import BaseLanguageModel\n",
    "from pydantic import BaseModel, Field\n",
    "import streamlit as st\n",
    "\n",
    "# Tool argument schemas\n",
    "class RagArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"The query to get course information for\")\n",
    "\n",
    "class ExplainArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"The query to explain\")\n",
    "    # previous_query: Optional[str] = Field(default=\"\", description=\"Previous query for context\")\n",
    "\n",
    "class ExerciseArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"The query to generate exercise for\")\n",
    "    previous_query: str = Field(default=\"\", description=\"Previous query for context\")\n",
    "    skill_level: str = Field(default=\"beginner\", description=\"Student's skill level\")\n",
    "    previous_exercise: str = Field(default=\"\", description=\"Previous exercise for context\")\n",
    "\n",
    "class AnalyticsArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"The query about data analytics\")\n",
    "    chat_history: str = Field(default=\"\", description=\"Previous chat history for context\")\n",
    "\n",
    "class DebugArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"The code or error to debug\")\n",
    "    chat_history: str = Field(default=\"\", description=\"Previous chat history for context\")\n",
    "\n",
    "class ChatArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"The message to respond to\")\n",
    "    \n",
    "\n",
    "# Tool definitions\n",
    "def rag_tool(chain):\n",
    "    \"\"\"Tool for retrieving course-related information.\"\"\"\n",
    "    def _run(args: RagArgs) -> str:\n",
    "        return chain.stream(args.query)\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=\"course_information\",\n",
    "        description=\"Use this tool for course-specific information, ex: instructor, syllabus, policies or assignments.\",\n",
    "        func=_run,\n",
    "        args_schema=RagArgs\n",
    "    )\n",
    "\n",
    "def explain_tool(chain):\n",
    "    \"\"\"Tool for explaining technical concepts.\"\"\"\n",
    "    def _run(args: ExplainArgs) -> str:\n",
    "        return chain.invoke({\"query\": args.query, \"chat_history\": args.previous_query})\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=\"explain_concept\",\n",
    "        description=\"Use this tool when the query asks for explanation of Python, SQL, or other concepts.\",\n",
    "        func=_run,\n",
    "        args_schema=ExplainArgs\n",
    "    )\n",
    "\n",
    "def exercise_tool(chain):\n",
    "    \"\"\"Tool for generating exercise questions.\"\"\"\n",
    "    def _run(args: ExerciseArgs) -> str:\n",
    "        return chain.invoke({\n",
    "            \"current_query\": args.query,\n",
    "            \"previous_query\": args.previous_query,\n",
    "            \"skill_level\": args.skill_level,\n",
    "            \"previous_exercise\": args.previous_exercise\n",
    "        })\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=\"generate_exercise\",\n",
    "        description=\"Use this tool when the query asks for Python or SQL practice exercises.\",\n",
    "        func=_run,\n",
    "        args_schema=ExerciseArgs\n",
    "    )\n",
    "\n",
    "def analytics_tool(chain):\n",
    "    \"\"\"Tool for data analytics explanations.\"\"\"\n",
    "    def _run(args: AnalyticsArgs) -> str:\n",
    "        return chain.invoke({\n",
    "            \"query\": args.query,\n",
    "            \"chat_history\": args.chat_history\n",
    "        })\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=\"explain_analytics\",\n",
    "        description=\"Use this tool when the query is about data analysis with pandas, matplotlib, seaborn, or statistics.\",\n",
    "        func=_run,\n",
    "        args_schema=AnalyticsArgs\n",
    "    )\n",
    "\n",
    "def debug_tool(chain):\n",
    "    \"\"\"Tool for debugging assistance.\"\"\"\n",
    "    def _run(args: DebugArgs) -> str:\n",
    "        return chain.invoke({\n",
    "            \"query\": args.query,\n",
    "            \"chat_history\": args.chat_history\n",
    "        })\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=\"debug_code\",\n",
    "        description=\"Use this tool when the query is about code errors or debugging help.\",\n",
    "        func=_run,\n",
    "        args_schema=DebugArgs\n",
    "    )\n",
    "\n",
    "def chat_tool(chain):\n",
    "    \"\"\"Tool for general conversation.\"\"\"\n",
    "    def _run(args, chat_history) -> str:\n",
    "        \n",
    "        print(\"--\"*10, \"inside the chat tool\")\n",
    "        print(args.query)\n",
    "        return chain.stream({\n",
    "            \"query\": args,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=\"general_chat\",\n",
    "        description=\"Use this tool for general conversation or when no other tools are appropriate.\",\n",
    "        func=_run,\n",
    "        args_schema=ChatArgs\n",
    "    )\n",
    "\n",
    "def create_tool_chain(llm: BaseLanguageModel, chain_dict: dict):\n",
    "    \"\"\"Create a tool-enabled LLM chain.\"\"\"\n",
    "    tools = [\n",
    "        # rag_tool(chain_dict['rag']),\n",
    "        explain_tool(chain_dict['explain']),\n",
    "        # exercise_tool(chain_dict['exercise']),\n",
    "        # analytics_tool(chain_dict['analytics']),\n",
    "        debug_tool(chain_dict['debug']),\n",
    "        chat_tool(chain_dict['chat'])\n",
    "    ]\n",
    "    \n",
    "    # Bind tools to LLM with system message\n",
    "    return llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "\n",
    "def chat_chain(llm):\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"You are a virtual teaching assistant for an Applied data analytics with Python class. Converse with the student in a friendly and engaging manner, considering the chat history. Your response should be concise and relevant to the student's query. Limit your response to 100 tokens.\"\"\"),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "    # setup = RunnableParallel(\n",
    "    #         {\"query\": RunnablePassthrough(),\n",
    "    #          \"chat_history\": RunnablePassthrough()\n",
    "    #          }\n",
    "    #     )\n",
    "        \n",
    "    # chain = setup | prompt | llm | output_parser\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    return chain\n",
    "# Setup LLM models\n",
    "gpt4o_mini = llms.openai_gpt4o_mini\n",
    "gpt4o_mini_json = llms.openai_4o_mini_json\n",
    "claude_sonnet = llms.claude_sonnet\n",
    "claude_haiku = llms.claude_haiku\n",
    "gpt4o = llms.openai_gpt4o\n",
    "\n",
    "# Create base chains\n",
    "chains_dict = {\n",
    "    # 'rag': chains.rag_chain(claude_haiku, retriever),\n",
    "    # 'exercise': chains.exercise_chain(claude_sonnet),\n",
    "    'chat': chat_chain(gpt4o_mini),\n",
    "    # 'chat': chains.chat_chain(gpt4o_mini),\n",
    "    'explain': chains.code_chain(claude_sonnet),\n",
    "    'debug': chains.code_chain(claude_haiku),\n",
    "}\n",
    "\n",
    "# Create tool chain\n",
    "tool_agent = create_tool_chain(gpt4o_mini, chains_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'general_chat', 'args': {'query': \"hi i'm lili\"}, 'id': 'call_Tn5SUZvv95wm9vt8frJa520x', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "user_query = \"hi i'm lili\"\n",
    "\n",
    "tool_call = tool_agent.invoke(\n",
    "            f\"\"\"\n",
    "            You're a helpful tool callling agent Your only task is to decide which tool to call based on the user query and chat history, and generate the appropriate arguements for the tool call.\n",
    "            \n",
    "            Query: {user_query}\\n\n",
    "            \"\"\")\n",
    "print(tool_call.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general_chat\n",
      "{'query': \"hi i'm lili\"}\n"
     ]
    }
   ],
   "source": [
    "name=tool_call.tool_calls[0][\"name\"]\n",
    "args=tool_call.tool_calls[0]['args']\n",
    "\n",
    "print(name)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Lili! Great to meet you! How's your journey in applied data analytics with Python going so far?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains.chat_chain(gpt4o_mini).invoke(input={\n",
    "    \n",
    "    \"query\": user_query,\n",
    "    \"chat_history\":\n",
    "    [(\"ai\", \"hi, how can i help you?\"),\n",
    "     \n",
    "     ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_tuples(messages):\n",
    "    chat_history = []\n",
    "    for message in messages:\n",
    "        if message['role'] == 'assistant':\n",
    "            chat_history.append((\"assistant\", message['content']))\n",
    "        elif message['role'] == 'user':\n",
    "            chat_history.append((\"human\", message['content']))  # note: 'user' becomes 'human'\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sure! here's a simple example:\n",
      "\n",
      "```python\n",
      "def calculate_discount(price, discount_rate):\n",
      "    discount = price * discount_rate\n",
      "    return price - discount\n",
      "\n",
      "final_price = calculate_discount(100, 0.2)\n",
      "print(f\"The final price after discount is: ${final_price}\")\n",
      "```\n",
      "\n",
      "in this example, the function calculates the final price after applying a discount, which is useful in a retail business context.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "chat_history = [\n",
    "    AIMessage(content=\"what's your name?\"),\n",
    "    HumanMessage(content=\"my name is lili\"),\n",
    "    AIMessage(content=\"hi lili, how can i help you?\"),\n",
    "    HumanMessage(content=\"can you explain what a function is in python?\"),\n",
    "    AIMessage(content=\"a function is a block of code that performs a specific task. it can take inputs, process them, and return an output. functions help organize code and make it reusable.\"),\n",
    "\n",
    "    ]\n",
    "\n",
    "user_query = \"give me an code example highlighting return value with business context\"\n",
    "\n",
    "chain = chat_chain(gpt4o_mini)\n",
    "\n",
    "response1 = chains_dict['chat'].invoke(\n",
    "    {\n",
    "        'query': user_query, \n",
    "    \"chat_history\": chat_history\n",
    "    # convert_to_openai_messages(chat_history)\n",
    "    }\n",
    ")\n",
    "print(response1)\n",
    "\n",
    "\n",
    "# response2 = chat_tool(chain).invoke(\n",
    "#     input={\n",
    "#         'args': ChatArgs(user_query) \n",
    "#     # \"chat_history\": chat_history\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# response = chat_tool(chain).func(\n",
    "#     args=ChatArgs(query=user_query),\n",
    "#     chat_history=chat_history\n",
    "# )\n",
    "# for chunk in response:\n",
    "#     print(chunk, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [AIMessage(content=\"what's your name?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='my name is lili', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='hi lili, how can i help you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='can you explain what a function is in python?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='a function is a block of code that performs a specific task. it can take inputs, process them, and return an output. functions help organize code and make it reusable.', additional_kwargs={}, response_metadata={})],\n",
       " 'query': 'can you explain what a function is in python?'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args={\"query\": \"can you explain what a function is in python?\",}\n",
    "\n",
    "{\n",
    "                'chat_history': chat_history,\n",
    "                **args}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
